{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Variational Autoencoder (SVAE)\n",
    "\n",
    "A Standard Variational Autoencoder (SVAE) is a sophisticated machine learning model designed for compressing and reconstructing data. It operates in two main phases:\n",
    "\n",
    "1. Encoding: The SVAE takes complex input data, such as Goodreads book reviews, and compresses it into a simplified, lower-dimensional representation. This process involves distilling the essential features and patterns from the data.\n",
    "2. Decoding: It then reconstructs the input data from this compact form. The reconstruction aims to be as close as possible to the original, retaining the critical elements of the input.\n",
    "\n",
    "\n",
    "The unique aspect of SVAEs is their 'variational' approach. Instead of representing an input as a single fixed point, they encode it as a range of possibilities, a distribution. This probabilistic method captures the inherent uncertainties and variations in the data, making the model more flexible and powerful.\n",
    "\n",
    "For a recommendation system using Goodreads book reviews, an SVAE can effectively learn the complex preferences and nuances in the reviews, facilitating accurate and personalized book suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Extending the system path to include the parent directory for module imports\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Local utility functions and model imports\n",
    "from src.utils import preprocess, metrics, build_features\n",
    "from src.models import SVAE\n",
    "\n",
    "# TensorFlow specific setup for disabling eager execution\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "# Suppressing warnings for a cleaner notebook presentation\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (91226, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74505</th>\n",
       "      <td>2540</td>\n",
       "      <td>A Game of Thrones (A Song of Ice and Fire, #1)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60643</th>\n",
       "      <td>5886</td>\n",
       "      <td>The Amazing Adventures of Kavalier &amp; Clay</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87603</th>\n",
       "      <td>4411</td>\n",
       "      <td>The World to Come</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81524</th>\n",
       "      <td>4934</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone (Harr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60556</th>\n",
       "      <td>5791</td>\n",
       "      <td>Bloodsucking Fiends (A Love Story, #1)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                                          book_name  rating\n",
       "74505     2540     A Game of Thrones (A Song of Ice and Fire, #1)       4\n",
       "60643     5886          The Amazing Adventures of Kavalier & Clay       4\n",
       "87603     4411                                  The World to Come       5\n",
       "81524     4934  Harry Potter and the Philosopher's Stone (Harr...       5\n",
       "60556     5791             Bloodsucking Fiends (A Love Story, #1)       3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading ratings data\n",
    "rating_file = os.path.join('..', 'src', 'data', 'goodreads_2m', 'ratings.csv')\n",
    "ratings = pd.read_csv(rating_file)\n",
    "\n",
    "# Displaying the shape of the dataset and a random sample of 5 entries\n",
    "print(f'Shape: {ratings.shape}')\n",
    "ratings.sample(5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61252, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Restaurant at the End of the Universe (Hit...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ready Player One (Ready Player One, #1)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bad Blood: Secrets and Lies in a Silicon Valle...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A Short History of Nearly Everything</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>The Collapsing Empire (The Interdependency, #1)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                          book_name  rating\n",
       "0        1  The Restaurant at the End of the Universe (Hit...       5\n",
       "1        1            Ready Player One (Ready Player One, #1)       4\n",
       "3        1  Bad Blood: Secrets and Lies in a Silicon Valle...       4\n",
       "4        1               A Short History of Nearly Everything       5\n",
       "5        1    The Collapsing Empire (The Interdependency, #1)       4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binarizing the dataset - retaining only ratings of 4 or higher\n",
    "df_preferred = ratings[ratings['rating'] >= 4]\n",
    "# Optionally handling lower ratings, if needed in future analysis\n",
    "df_low_rating = ratings[ratings['rating'] < 4]\n",
    "\n",
    "print(df_preferred.shape)\n",
    "df_preferred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61245, 3)\n"
     ]
    }
   ],
   "source": [
    "# Filtering users with at least 5 reviews (unnecessary because of previous filtering)\n",
    "df_filtered_users = df_preferred.groupby('user_id').filter(lambda x: len(x) >= 5)\n",
    "\n",
    "# Filtering books reviewed by at least one user\n",
    "df_final = df_filtered_users.groupby('book_name').filter(lambda x: len(x) >= 1)\n",
    "\n",
    "# Displaying the shape of the final filtered dataset\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 91226 book reviews from 1368 users and 2718 books (sparsity: 2.453%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the count of unique users and books\n",
    "usercount = df_final.groupby('user_id', as_index=False).size().rename(columns={'size': 'user_count'})\n",
    "itemcount = df_final.groupby('book_name', as_index=False).size().rename(columns={'size': 'book_count'})\n",
    "\n",
    "# Compute sparsity of the dataset after filtering\n",
    "total_ratings = ratings.shape[0]\n",
    "num_users = usercount.shape[0]\n",
    "num_books = itemcount.shape[0]\n",
    "sparsity = 1. * total_ratings / (num_users * num_books)\n",
    "\n",
    "print(f\"After filtering, there are {total_ratings} book reviews from {num_users} users and {num_books} books (sparsity: {sparsity * 100:.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split the unique users into train, validation, and test sets\n",
    "unique_users = sorted(df_final.user_id.unique())\n",
    "np.random.seed(123)\n",
    "unique_users = np.random.permutation(unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 1368\n",
      "\n",
      "Number of training users: 968\n",
      "\n",
      "Number of validation users: 200\n",
      "\n",
      "Number of test users: 200\n"
     ]
    }
   ],
   "source": [
    "HELDOUT_USERS = 200  # Number of users to hold out for validation and test sets\n",
    "\n",
    "# Splitting the unique users\n",
    "n_users = len(unique_users)\n",
    "train_users = unique_users[:(n_users - HELDOUT_USERS * 2)]\n",
    "val_users = unique_users[(n_users - HELDOUT_USERS * 2):(n_users - HELDOUT_USERS)]\n",
    "test_users = unique_users[(n_users - HELDOUT_USERS):]\n",
    "\n",
    "print(\"Number of unique users:\", n_users)\n",
    "print(\"\\nNumber of training users:\", len(train_users))\n",
    "print(\"\\nNumber of validation users:\", len(val_users))\n",
    "print(\"\\nNumber of test users:\", len(test_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training observations: 44171\n",
      "\n",
      "Number of validation observations: 8374\n",
      "\n",
      "Number of test observations: 8700\n"
     ]
    }
   ],
   "source": [
    "# Filtering the dataset for training, validation, and test sets based on the user splits\n",
    "train_set = df_final[df_final['user_id'].isin(train_users)]\n",
    "val_set = df_final[df_final['user_id'].isin(val_users)]\n",
    "test_set = df_final[df_final['user_id'].isin(test_users)]\n",
    "\n",
    "print(\"Number of training observations:\", train_set.shape[0])\n",
    "print(\"\\nNumber of validation observations:\", val_set.shape[0])\n",
    "print(\"\\nNumber of test observations:\", test_set.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique books rated in training set: 2712\n"
     ]
    }
   ],
   "source": [
    "# Identifying unique books in the training set\n",
    "unique_train_items = pd.unique(train_set['book_name'])\n",
    "print(f\"Number of unique books rated in training set: {unique_train_items.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation observations after filtering: 8364\n",
      "\n",
      "Number of test observations after filtering: 8694\n"
     ]
    }
   ],
   "source": [
    "# Filtering validation and test sets to include only books from the training set\n",
    "val_set = val_set[val_set['book_name'].isin(unique_train_items)]\n",
    "print(f\"Number of validation observations after filtering: {val_set.shape[0]}\")\n",
    "\n",
    "test_set = test_set[test_set['book_name'].isin(unique_train_items)]\n",
    "print(f\"\\nNumber of test observations after filtering: {test_set.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating affinity matrices for train, validation, and test sets\n",
    "am_train = build_features.AffinityMatrix(df=train_set, items_list=unique_train_items)\n",
    "am_val = build_features.AffinityMatrix(df=val_set, items_list=unique_train_items)\n",
    "am_test = build_features.AffinityMatrix(df=test_set, items_list=unique_train_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(968, 2712)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2712)\n",
      "(200, 2712)\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the sparse matrices\n",
    "train_data, _, _ = am_train.gen_affinity_matrix()\n",
    "print(train_data.shape)\n",
    "\n",
    "val_data, val_map_users, val_map_items = am_val.gen_affinity_matrix()\n",
    "print(val_data.shape)\n",
    "\n",
    "test_data, test_map_users, test_map_items = am_test.gen_affinity_matrix()\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified splitting for validation and test sets\n",
    "val_data_tr, val_data_te = preprocess.numpy_stratified_split(val_data, ratio=0.75, seed=123)\n",
    "test_data_tr, test_data_te = preprocess.numpy_stratified_split(test_data, ratio=0.75, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizing data based on a threshold\n",
    "threshold = 3.5\n",
    "train_data = np.where(train_data > threshold, 1.0, 0.0)\n",
    "val_data_tr = np.where(val_data_tr > threshold, 1.0, 0.0)\n",
    "val_data_te_ratings = val_data_te.copy()\n",
    "val_data_te = np.where(val_data_te > threshold, 1.0, 0.0)\n",
    "test_data_tr = np.where(test_data_tr > threshold, 1.0, 0.0)\n",
    "test_data_te_ratings = test_data_te.copy()\n",
    "test_data_te = np.where(test_data_te > threshold, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve real ratings from initial dataset \n",
    "test_data_te_ratings=pd.DataFrame(test_data_te_ratings)\n",
    "val_data_te_ratings=pd.DataFrame(val_data_te_ratings)\n",
    "\n",
    "for index,i in df_low_rating.iterrows():\n",
    "    user_old= i['user_id'] # old value \n",
    "    item_old=i['book_name'] # old value \n",
    "\n",
    "    if (test_map_users.get(user_old) is not None)  and (test_map_items.get(item_old) is not None) :\n",
    "        user_new=test_map_users.get(user_old) # new value \n",
    "        item_new=test_map_items.get(item_old) # new value \n",
    "        rating=i['rating'] \n",
    "        test_data_te_ratings.at[user_new,item_new]= rating   \n",
    "\n",
    "    if (val_map_users.get(user_old) is not None)  and (val_map_items.get(item_old) is not None) :\n",
    "        user_new=val_map_users.get(user_old) # new value \n",
    "        item_new=val_map_items.get(item_old) # new value \n",
    "        rating=i['rating'] \n",
    "        val_data_te_ratings.at[user_new,item_new]= rating   \n",
    "\n",
    "\n",
    "val_data_te_ratings=val_data_te_ratings.to_numpy()    \n",
    "test_data_te_ratings=test_data_te_ratings.to_numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration parameters\n",
    "INTERMEDIATE_DIM = 200\n",
    "LATENT_DIM = 64\n",
    "EPOCHS = 400\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# Initialize the SVAE model with specified parameters\n",
    "model = SVAE.StandardVAE(n_users=train_data.shape[0],  # Number of unique users\n",
    "                         original_dim=train_data.shape[1],  # Number of unique items\n",
    "                         intermediate_dim=INTERMEDIATE_DIM,\n",
    "                         latent_dim=LATENT_DIM,\n",
    "                         n_epochs=EPOCHS,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         k=10,  # Number of items to recommend\n",
    "                         verbose=0,\n",
    "                         seed=123,  # Seed for reproducibility\n",
    "                         drop_encoder=0.5,  # Dropout rate for encoder\n",
    "                         drop_decoder=0.5,  # Dropout rate for decoder\n",
    "                         annealing=False,  # Whether to use annealing\n",
    "                         beta=1.0)  # Beta parameter for VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:fg:1: no job control in this shell.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 14:16:53.844928: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2024-01-31 14:16:53.857529: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-01-31 14:16:53.920355: W tensorflow/c/c_api.cc:291] Operation '{name:'training/Adam/dense_3/bias/v/Assign' id:563 op device:{requested: '', assigned: ''} def:{{{node training/Adam/dense_3/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/dense_3/bias/v, training/Adam/dense_3/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-01-31 14:16:54.146599: W tensorflow/c/c_api.cc:291] Operation '{name:'loss/mul' id:202 op device:{requested: '', assigned: ''} def:{{{node loss/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul/x, loss/dense_4_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-01-31 14:16:54.194227: W tensorflow/c/c_api.cc:291] Operation '{name:'dense_4/Softmax' id:159 op device:{requested: '', assigned: ''} def:{{{node dense_4/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](dense_4/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "!%%time\n",
    "model.fit(x_train=train_data,\n",
    "          x_valid=val_data,\n",
    "          x_val_tr=val_data_tr,\n",
    "          x_val_te=val_data_te_ratings,  # Validation data with original ratings\n",
    "          mapper=am_val)  # AffinityMatrix instance for validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating recommendations for the test set\n",
    "top_k = model.recommend_k_items(x=test_data_tr, k=10, remove_seen=True)\n",
    "\n",
    "# Mapping the sparse matrix back to a DataFrame for further analysis\n",
    "recommendations = am_test.map_back_sparse(top_k, kind='prediction')\n",
    "test_df = am_test.map_back_sparse(test_data_te_ratings, kind='ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "The performance of our model is evaluated using the test set, which consists of the exact same users in the training set but with books the users have reviewed that the model has not seen before. A good model will recommend books that the user has also reviewed in the test set.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Precision@k\n",
    "\n",
    "Out of the books that are recommended, what proportion is relevant. Relevant in this case is if the user has reviewed the book.\n",
    "\n",
    "A precision@10 of about 0.1 means that about 10% of the recommendations are relevant to the user. In other words, out of the 10 recommendations made, on average a user will have 1 book that is actually relevant.\n",
    "\n",
    "### Recall@k\n",
    "\n",
    "Out of all the relevant books (in the test set), how many are recommended.\n",
    "\n",
    "A recall@10 of 0.1 means that about 10% of the relevant books were recommended. By definition you can see how even if all the recommendations made were relevant, recall@k is capped by k. A higher k means that more relevant books can be recommended.\n",
    "\n",
    "### Mean Average Precision (MAP)\n",
    "\n",
    "Calculate the average precision for each user and average all the average precisions over all users. Penalizes incorrect rankings of books.\n",
    "\n",
    "### Normalized Discounted Cumulative Gain (NDGC)\n",
    "\n",
    "Looks at both relevant books and the ranking order of the relevant books. Normalized by the total number of users.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVAE performance below shows much better results in comparison to SVD with Precision@k = 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.207000\n",
      "Recall: 0.071519\n",
      "MAP: 0.041507\n",
      "NDCG: 0.216293\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model performance\n",
    "top_k = recommendations.copy()\n",
    "top_k['rank'] = top_k.groupby('user_id', sort=False).cumcount() + 1\n",
    "precision_at_k = metrics.precision_at_k(top_k, test_df, 'user_id', 'book_name', 'rank')\n",
    "recall_at_k = metrics.recall_at_k(top_k, test_df, 'user_id', 'book_name', 'rank')\n",
    "mean_average_precision = metrics.mean_average_precision(top_k, test_df, 'user_id', 'book_name', 'rank')\n",
    "ndcg = metrics.ndcg(top_k, test_df, 'user_id', 'book_name', 'rank')\n",
    "\n",
    "# Printing performance metrics\n",
    "print(f'Precision: {precision_at_k:.6f}',\n",
    "      f'Recall: {recall_at_k:.6f}',\n",
    "      f'MAP: {mean_average_precision:.6f}',\n",
    "      f'NDCG: {ndcg:.6f}', sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
